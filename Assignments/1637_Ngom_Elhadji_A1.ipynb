{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 1</h1>\n",
    "\n",
    "<p>In this first assignment we are focusing on a classification problem.<br>\n",
    "Our goal will be to use both the <b>K-Nearest Neighbors</b> and the <b>Decision Tree</b> techniques and try to compare the predictive models obtained.</p>\n",
    "\n",
    "<h3>The Dataset</h3>\n",
    "<p>For this assignment we will be using the sonar_train.csv data set</p>\n",
    "<p>This data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for mines and 180 degrees for rocks. Each sample is a set of 60 numbers in the range 0.0 to 1.0, where each number represents the energy within a particular frequency band (integrated over a certain period of time). The output target contains the letter R if the object is a rock and M if it is a mine (metal cylinder).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Opening the sonar_train.csv file\n",
    "data = pd.read_csv('sonar.csv')\n",
    "\n",
    "###Display informations and the different column/features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      "Band1     208 non-null float64\n",
      "Band2     208 non-null float64\n",
      "Band3     208 non-null float64\n",
      "Band4     208 non-null float64\n",
      "Band5     208 non-null float64\n",
      "Band6     208 non-null float64\n",
      "Band7     208 non-null float64\n",
      "Band8     208 non-null float64\n",
      "Band9     208 non-null float64\n",
      "Band10    208 non-null float64\n",
      "Band11    208 non-null float64\n",
      "Band12    208 non-null float64\n",
      "Band13    208 non-null float64\n",
      "Band14    208 non-null float64\n",
      "Band15    208 non-null float64\n",
      "Band16    208 non-null float64\n",
      "Band17    208 non-null float64\n",
      "Band18    208 non-null float64\n",
      "Band19    208 non-null float64\n",
      "Band20    208 non-null float64\n",
      "Band21    208 non-null float64\n",
      "Band22    208 non-null float64\n",
      "Band23    208 non-null float64\n",
      "Band24    208 non-null float64\n",
      "Band25    208 non-null float64\n",
      "Band26    208 non-null float64\n",
      "Band27    208 non-null float64\n",
      "Band28    208 non-null float64\n",
      "Band29    208 non-null float64\n",
      "Band30    208 non-null float64\n",
      "Band31    208 non-null float64\n",
      "Band32    208 non-null float64\n",
      "Band33    208 non-null float64\n",
      "Band34    208 non-null float64\n",
      "Band35    208 non-null float64\n",
      "Band36    208 non-null float64\n",
      "Band37    208 non-null float64\n",
      "Band38    208 non-null float64\n",
      "Band39    208 non-null float64\n",
      "Band40    208 non-null float64\n",
      "Band41    208 non-null float64\n",
      "Band42    208 non-null float64\n",
      "Band43    208 non-null float64\n",
      "Band44    208 non-null float64\n",
      "Band45    208 non-null float64\n",
      "Band46    208 non-null float64\n",
      "Band47    208 non-null float64\n",
      "Band48    208 non-null float64\n",
      "Band49    208 non-null float64\n",
      "Band50    208 non-null float64\n",
      "Band51    208 non-null float64\n",
      "Band52    208 non-null float64\n",
      "Band53    208 non-null float64\n",
      "Band54    208 non-null float64\n",
      "Band55    208 non-null float64\n",
      "Band56    208 non-null float64\n",
      "Band57    208 non-null float64\n",
      "Band58    208 non-null float64\n",
      "Band59    208 non-null float64\n",
      "Band60    208 non-null float64\n",
      "Type      208 non-null object\n",
      "dtypes: float64(60), object(1)"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this data set each band is a feature and the target is the type of the object</p>\n",
    "<h4> <u>QUESTION 1 :</u> How many samples and how many features do we have?</h4>\n",
    "<p><i>Type your answer here: </i></p>\n",
    "<h4><u></u> We have 208 samples and each sample has 60 features.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###using the train_test_split command split the data set in two : 'train' and 'test' with a ratio ~75%-25%\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(data, train_size=0.75)\n",
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 61)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 61) , There is 97 letters R\n"
     ]
    }
   ],
   "source": [
    "#The last column in our sets correspond to the target\n",
    "###Count how many of 'R' and 'M' you have in total\n",
    "R = data[data.Type=='R']\n",
    "M = data[data.Type=='M']\n",
    "print np.shape(R), ', There is 97 letters R'\n",
    "#R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 61) , There is also 111 letters M\n"
     ]
    }
   ],
   "source": [
    "print np.shape(M), ', There is also 111 letters M'\n",
    "#M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#In order to make targets more easily usable we will replace 'R' and 'M' by 0 and 1 respectively.\n",
    "###Do it for both sets using the command : .replace()\n",
    "train_01 = train.replace(['M','R'],[1,0])\n",
    "test_01 = test.replace(['M','R'],[1,0])\n",
    "test_01.Type \n",
    "train_01_fin = train.drop('Type', axis = 1)\n",
    "test_01_fin = test.drop('Type', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K-Nearest Neighbors approach</h3>\n",
    "\n",
    "<p>In this section we will apply the <b>K-Nearest Neighbors</b> technique to the data set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "###Fille the brackets to use the brute force approach and 7 neighbors\n",
    "knn = KNeighborsClassifier(algorithm='brute',n_neighbors=7)\n",
    "#################################################################\n",
    "### Train the Nearest Neighbor Classifier \"knn\" on the training set\n",
    "knn.fit(train_01_fin,train_01.Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 2 :</u> Which kind of impact has the choice of the algorithm?</h4>\n",
    "<p><i>Type your answer here: </i></p>\n",
    "<h4> Imroving the accuracy </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': 1,\n",
       " 'n_neighbors': 7,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#At any time it is possible to recall the parameters using :\n",
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We now want to test the accuracy of the nearest neighbor classifier</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "###Compute the target prediction for the elements of the test set and compare with their true value\n",
    "predict = knn.predict(test_01_fin)\n",
    "print predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807692307692\n"
     ]
    }
   ],
   "source": [
    "#scikit actually includes an accuracy evaluation function :\n",
    "#Compute the accuracy using knn.score()\n",
    "accuracy = knn.score(test_01_fin,test_01.Type)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 3 :</u> Is the accuracy acceptable?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "<h4>Yes, it is acceptable </h4>\n",
    "\n",
    "\n",
    "<p>In the following cell repeat the training and the test steps with different knn parameters and try to find a good combination.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846153846154\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto',n_neighbors=7,leaf_size=25,p=1,weights='distance')\n",
    "knn.fit(train_01_fin,train_01.Type)\n",
    "predict = knn.predict(test_01_fin)\n",
    "accuracy = knn.score(test_01_fin,test_01.Type)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 4 :</u> What is the best accuracy you get? What can you conclude?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "<p><i><h4>The accuracy is improved </h4> </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Tree</h3>\n",
    "\n",
    "<p>Using the same sets we now investigate the efficiency of a <b>decision tree classifier<b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dtr = tree.DecisionTreeClassifier()\n",
    "# train the decision tree classifier \"dtr\" <<<max_depth=5,max_leaf_nodes=30,splitter='best'\n",
    "dtr.fit(train_01_fin,train_01.Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as previously we can display some informations\n",
    "dtr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <u>QUESTION 5 :</u> From the list above, give the keywords influencing the test performed at a decison node?</h4>\n",
    "<p><i>Type your answer here</i></p>\n",
    "<p><i>The keywords influencing the test performed at a decison node are:<h4> 'max_leaf_nodes', 'splitter', 'min_samples_split' and 'max_depth'  </h4></i></p>\n",
    "<p>In the follwing, using the work done previously test the accuracy of the decision tree classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788461538462\n"
     ]
    }
   ],
   "source": [
    "predict1 = dtr.predict(test_01_fin)\n",
    "####################################\n",
    "accu = dtr.score(test_01_fin,test_01.Type)\n",
    "print accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Hereafter, using different parameters for our decision tree, try to improve the accuracy</p>\n",
    "\n",
    "<h4> <u>QUESTION 6 :</u> Explain which parameter(s) you plan to change and why?</h4>\n",
    "<p><i>Type your answer here:</i></p>\n",
    "<h4> min_samples_split, it impacts in the accuracy.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826923076923\n"
     ]
    }
   ],
   "source": [
    "dtr = tree.DecisionTreeClassifier(min_samples_split=1,max_depth=5,max_leaf_nodes=30,splitter='best')\n",
    "dtr.fit(train_01_fin,train_01.Type)\n",
    "predict1 = dtr.predict(test_01_fin)\n",
    "accu = dtr.score(test_01_fin,test_01.Type)\n",
    "print accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The results are different but obviously when we identify mines we don't want to be wrong.</p>\n",
    "\n",
    "<h4> <u>QUESTION 7 :</u> Which one of the two methods is better? Is the accuracy acceptable? Why?</h4>\n",
    "<p><i>Type your answer here :</i></p> \n",
    "<h4>Decision Tree, yes its accuracy better.   </h4> \n",
    "\n",
    "<h4> <u>QUESTION 8 :</u> What can you conclude from the whole study</h4>\n",
    "<p><i>Type your answer here:  </i></p>\n",
    "<h4>The study shows that Decision Tree has more precise accuracy  than KNN</h4>\n",
    "\n",
    "<h4> <u>BONUS :</u> Copy/Paste the code to generate a pdf file containing the best tree and attach the file generated to your assignment when sending everything to me</h4>\n",
    "<p> Remark:</p>\n",
    "<h4> Parser is not working until now, it will work in your computer. </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "f = tree.export_graphviz(dtr,out_file = dot_data,\n",
    "                         filled=True,rounded=True)\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_pdf('sonar.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
